# Inferential statistics, correlation and regression (A-level Geography Scottish Qualifications Authority)

## Introduction: why inferential statistics matter in geography
Inferential statistics allow geographers to move beyond description and to test hypotheses about relationships and patterns in the landscape. When you carry out fieldwork—measuring pebble size downstream, recording vegetation cover across a dune system, or surveying pedestrian flows in an urban centre—you rarely work with data for the whole population. Inferential methods give a way to decide whether observed patterns are likely to be real or simply the result of chance, to quantify the strength of relationships between variables, and to make limited predictions. In Advanced Higher Geography you will be expected to select appropriate inferential tests, justify your choice in the context of your data and research question, carry out or interpret the results of those tests, and explain what those results mean in geographical terms.

## Types of data and choosing the correct test
Choosing the right statistical technique starts with recognising the type of data you have. Nominal data are labels or categories such as rock type or land-use class; ordinal data are ranked but not evenly spaced, for example pebble angularity measured as rounded, sub-rounded, sub-angular and angular; interval or ratio (continuous) data have meaningful numeric differences and include measurements such as pebble diameter, distance downstream, temperature or flow velocity. For relationships between two continuous variables that show an approximately linear trend, Pearson’s product-moment correlation and linear regression are appropriate. When one or both variables are ordinal, when data contain clear outliers, or when the relationship is monotonic but not linear, Spearman’s rank correlation is usually a better choice. Categorical comparisons—such as whether two different zones contain different frequencies of a feature—require tests such as chi-squared. Spatial patterning of point features is tested by measures such as nearest neighbour analysis. Always state your null hypothesis (for example, “there is no relationship between pebble size and distance downstream”) and choose the test that matches the level of measurement, the distribution of your data, and the sampling method you used.

## Correlation: Pearson’s r and Spearman’s rho — what they tell you
Correlation quantifies the strength and direction of an association between two variables; it does not prove causation. Pearson’s r measures the strength of a linear relationship between two continuous variables. Conceptually, r is the covariance of the two variables divided by the product of their standard deviations, and it ranges from −1 (perfect negative linear relationship) to +1 (perfect positive linear relationship), with 0 indicating no linear association. The square of Pearson’s r, commonly reported as R² in regression contexts, gives the proportion of variance in one variable that can be explained by the other, expressed as a percentage. Spearman’s rank correlation coefficient, often written as rho (ρ), works on ranks rather than raw values and measures the strength of a monotonic relationship. It is useful when data are ordinal, when you have non-linear monotonic relationships, or when the data contain outliers that would distort Pearson’s r. In practice, choose Spearman’s if your variable values are rankings or if a scatterplot shows a curved but consistently increasing or decreasing pattern.

When you carry out a correlation test you should plot the data first. A scatterplot will show whether the relationship looks linear, whether any outliers are present, and whether there are distinct subsets in the sample. After testing, report the test statistic and the significance level. In exam answers and field reports, phrase your interpretation in geographical terms: rather than saying “r = −0.72”, say “there is a strong negative linear relationship (r = −0.72, p < 0.01) indicating that pebble size decreases markedly with increasing distance downstream.”

## Regression: fitting a line, interpreting slope, predictions and limitations
Regression is the next step after correlation when you want to model the relationship and, sometimes, make predictions. Simple linear regression fits the best straight line through your data in the form y = a + bx, where b is the slope and a is the intercept. The slope b tells you the expected change in the dependent variable y for a one-unit increase in the independent variable x; in a river study the slope might quantify the average reduction in pebble diameter for every metre downstream. The coefficient of determination, R², indicates how much of the variability in y is accounted for by x; an R² of 0.45 means 45% of the variance is explained by the model while the remaining 55% is due to other factors or random variation.

Always check the assumptions of linear regression: the relationship should be approximately linear, residuals (the differences between observed and predicted values) should be roughly normally distributed and show no pattern when plotted against predicted values, and variance should be homoscedastic (constant across the range of predictions). If residuals fan out or show structure, the model may be inappropriate and transformations (for example log transforms) or a different model may be needed. Use regression with care for prediction. Extrapolating beyond the observed range of x is hazardous because the relationship may change outside the study area or time frame. Also remember that a statistically significant slope does not by itself establish a causal mechanism: use your geographical knowledge to evaluate whether a causal interpretation is reasonable.

## Other inferential techniques useful in geographical research: chi-squared and nearest neighbour
Chi-squared analysis tests whether observed frequencies in categories differ from expected frequencies under a null hypothesis. It is appropriate when your data are nominal, such as counts of shell types across dune zones or numbers of shops of different categories in neighbourhoods. The test statistic is the sum of (observed minus expected) squared divided by expected for all categories, and degrees of freedom are calculated as (rows − 1) × (columns − 1) in contingency tables. A common rule of thumb is that expected frequencies should generally be five or more in each cell for the usual chi-squared approximation to be reliable; if many expected counts are small, consider combining categories or using an exact test. In reporting, state the chi-squared value, the degrees of freedom and the p-value, then explain what this means in context: for example, “the chi-squared test (χ² = 12.6, df = 2, p < 0.01) shows that observed shell type frequencies differ significantly between the foredune, mid-dune and back-dune zones, suggesting non-random distribution.”

Nearest neighbour analysis quantifies spatial patterning of point features such as settlements, trees, or shop locations. The method compares the observed mean nearest-neighbour distance to the expected mean distance under complete spatial randomness. The ratio R = observed mean distance / expected mean distance indicates clustering if R < 1, randomness if R ≈ 1, and regularity if R > 1. Expected distance is inversely related to the square root of point density, so the calculation depends on the study area being well-defined. Interpreting nearest neighbour results requires care because edge effects, sample size and distribution density all affect the index. Use maps and density plots alongside the index to present a more complete spatial story.

## Fieldwork, sampling and data-processing practicalities
Every inferential test rests on data that were collected appropriately. Sampling design is therefore critical. Random sampling reduces bias and allows inferential statistics to be legitimately applied; stratified sampling is useful when the study area has clear subzones and you want to ensure representation; regular or systematic sampling is often practical in the field but can interact with periodic spatial structures and thus should be used thoughtfully. Always record exactly how you sampled and any departures from the planned method, since these affect what you can legitimately infer.

Before testing, visualise the data with appropriate graphs. Histograms and box plots help reveal skewness and outliers; scatterplots reveal the form of bivariate relationships and whether transformations are appropriate; transect diagrams or kite diagrams place numerical data into spatial context. Descriptive statistics, including measures of central tendency and dispersion, are a necessary first step: they summarise the data and guide your choice of inferential techniques. When processing data, be explicit about how you handled ties in ranks (relevant for Spearman’s test), missing values, and any transformations you applied. If you use calculators, spreadsheets or statistical software, retain intermediate outputs so that you can show your working if required in an examination or in your project–folio.

## Common pitfalls and how to avoid them
A few mistakes recur in student work and cost marks. The most important is confusing correlation and causation; always consider alternative explanations and use theory and field evidence to justify causal claims. Small sample sizes reduce statistical power and make it harder to detect real relationships, so interpret non-significant results cautiously and report sample sizes. Outliers can dramatically change Pearson’s r and regression slopes; inspect and justify any decision to exclude outliers. Using the wrong test for the data type is another common error, for example applying Pearson’s r to ranked data or to heavily skewed variables without transformation. In chi-squared tests remember to check expected frequencies and combine categories if necessary. When reporting results, always include both the numerical outcome (test statistic, degrees of freedom and p-value where appropriate) and a plain-English interpretation that links back to the geographical question.

## Exam technique
In an examination or in your project write-up, structure answers about inferential statistics clearly and consistently. Start by stating the research hypothesis and the null hypothesis, and explain briefly why the chosen test is appropriate for the data type and sampling method. Show a clear plan: describe the variables and their measurement level, state any transformations, and outline the steps of the test. If a calculation is required, show key steps or intermediate results and state your final test statistic with degrees of freedom and p-value; if you used a calculator or software, indicate that and give the output values. Always interpret the numerical result in geographical terms: for example, after reporting r and p, say what the relationship implies about the physical or human process you studied. Where possible, relate statistical findings to maps, graphs and field observations to strengthen your interpretation. Finally, be explicit about limitations: comment on sample size, possible sampling bias, the effect of outliers, and whether the result supports a causal claim or merely indicates association. A concise conclusion that answers the initial research question, grounded in the statistical results and geographical reasoning, will secure the best marks.