# Descriptive statistics and data summarising (A-level Geography Scottish Qualifications Authority)

## Overview and purpose
Descriptive statistics are the essential bridge between raw geographical observations and meaningful interpretation. In Advanced Higher Geography you will collect numerical and categorical data through fieldwork or use secondary datasets, and you will need to reduce that information into clear summaries that reveal patterns, spread and relationships. Descriptive techniques help you to describe a typical value, to measure how variable the data are, and to present results visually so that trends and anomalies are immediately apparent. These summaries are not an end in themselves: they support analysis, help to test hypotheses, and form the evidence on which reasoned, geographically grounded conclusions are based.

## Types of data and sampling considerations
Understanding the nature of your data is the first step in choosing appropriate summary measures and tests. Nominal data are labels or categories where there is no natural order; ordinal data carry a rank order but not equal intervals between ranks; interval and ratio data are numerical and allow arithmetic operations, with ratio scales having a true zero. The distinction matters because measures such as the median can be used for ordinal data but the mean requires interval or ratio measurements. Equally important is how you gather data in the field or select cases from secondary sources. Random sampling gives each unit an equal chance of selection and avoids systematic bias; regular sampling, for example at fixed intervals along a transect, gives good spatial coverage; stratified sampling targets subgroups so that each is represented proportionately and can be vital when hazards or extremes mean simple random sampling would miss important variation. When planning, think about sample size, accessibility and safety: group collection of field data is acceptable so long as you acknowledge where values were recorded by teams and ensure a consistent protocol.

## Measures of central tendency and dispersion
To summarise a dataset you will typically report one measure of central tendency and at least one measure of dispersion. The mean is the arithmetic average and is useful when values are measured on an interval or ratio scale and the distribution is reasonably symmetric. The median, the middle value when observations are ordered, is less affected by extreme values and therefore preferable when outliers or skewness are present. The mode identifies the most frequent category and is the only central measure suitable for nominal data.

Dispersion describes how spread out values are. The simplest measure is the range, the difference between the maximum and minimum, which gives a quick sense of spread but is highly sensitive to outliers. The interquartile range (IQR) describes the spread of the middle 50% and is robust against extremes; it is also the basis of boxplot visualisation. The standard deviation quantifies the average distance of values from the mean and is essential when you wish to compare variation across datasets measured on the same scale. Linked to this, the standard error of the mean gives an indication of how precisely the sample mean estimates the population mean, and the coefficient of variation expresses standard deviation as a percentage of the mean, enabling comparison between series with very different units or magnitudes. In fieldwork write-ups it is good practice to explain why you chose particular measures, for example preferring median and IQR for skewed pebble size distributions and mean and standard deviation for near-normal temperature readings.

## Graphical and map-based presentation
Visual presentation is as important as numerical summary. Histograms and frequency polygons show the distribution of interval or ratio variables and make skew and modality easy to see. Boxplots neatly display median, IQR and potential outliers, and are particularly useful for comparing distributions at several sites or along a transect. Scattergraphs reveal relationships between two quantitative variables and can be annotated with a line of best fit to indicate direction and strength. For circular or directional data, polar graphs and rose diagrams are more suitable, and kite or dispersion diagrams are well suited to showing changes in a variable across a profile, such as pebble size across a beach or boulder size downriver.

Maps and map-based diagrams are vital for spatially referenced data. Choropleth maps show area-level intensity by shading, but they must use appropriate class intervals and consider the modifiable areal unit problem. Proportional symbol maps display absolute values at point locations and are visually intuitive for counts or magnitudes. Isoline maps represent continuous gradients such as temperature or elevation, while flow-line maps communicate movement, such as commuter flows or migration. Annotated overlays and transect maps allow you to combine quantitative graphs with map context; for instance, a transect overlay on an OS map can be paired with cross-section graphs to link spatial location to measured environmental variables. Always include clear legends, labelled axes, units and scales, and choose presentation types that match the message you want the map or graph to convey.

## Inferential tools and testing relationships
Beyond description, inferential techniques let you test whether observed patterns are likely to be real or could have arisen by chance. Correlation quantifies the strength and direction of association between two variables. Spearman’s rank correlation coefficient is non-parametric and appropriate for ordinal data or when assumptions of normality are doubtful, while Pearson’s product-moment correlation assumes interval or ratio data and a linear relationship; Pearson’s is more powerful when its assumptions are met. Linear regression fits a model predicting one variable from another and helps quantify the rate of change; it also provides residuals that can be examined for model fit and anomalies.

Chi-squared analysis compares observed and expected frequencies in categorical data and is useful, for instance, when testing whether two pebble types are distributed differently across zones. Nearest neighbour analysis is a spatial statistic that tells you whether a pattern of points, such as settlement locations, is clustered, random or regularly spaced. When applying inferential tests be explicit about hypotheses, state whether you are using a one-tailed or two-tailed approach, and be aware of sample size and distributional assumptions. Statistical significance does not prove causation; interpret results in the light of geographical processes and supporting evidence.

## Applying statistics in fieldwork and projects
Good statistical practice begins in the planning stage. Formulate a clear hypothesis or research question, decide the data types you need, and choose sampling and measurement methods that are repeatable. In the field, consistent procedures reduce measurement error: use the same instruments and timing for microclimate readings, sample pebbles using a fixed method across transects, and record metadata such as date, time and weather. Back in the classroom, begin data handling by cleaning the dataset: check for transcription errors, record missing values clearly, convert categorical labels into consistent codes, and decide how to treat any outliers (investigate their cause rather than deleting by default).

Select graphical and numerical summaries that make your results easy to interpret and justify those choices in the methods section of your write-up. For example, an investigation of boulder size downstream might report mean and standard deviation where samples are sufficiently regular, but present medians and IQRs for reach sections influenced by occasional very large cobbles. Use scattergraphs with a fitted regression line to examine relationships between distance downstream and pebble size, and accompany any inferential test with a short interpretation in plain language: explain what the coefficient means in geographic terms, and whether the relationship is likely to be physically meaningful. Wherever possible, triangulate: combine statistical evidence with map-based presentation and qualitative observations, such as visible changes in channel form or changes in depositional environment.

## Communicating findings and avoiding common pitfalls
Clear communication of statistical results is as important as the analysis itself. Always label axes with units, state sample sizes, and present measures of uncertainty where appropriate. Avoid misleading graphics: do not truncate axes to exaggerate trends, be careful with class intervals on choropleth maps, and remember that proportional symbol maps can mislead if symbol scaling is not perceptually uniform. Be cautious about ecological fallacies when making inferences about individuals from area-level data, and avoid conflating correlation with causation by considering alternative explanations and confounding variables.

Discuss limitations candidly: describe sampling constraints, instrument precision, potential sources of bias and how these affect confidence in your conclusions. Use statistical language precisely: distinguish between describing a pattern and claiming it is statistically significant, and explain what statistical significance means in the context of your question. In fieldwork reports and the project–folio, integrate quantitative results into a wider geographical narrative so that numbers support, rather than replace, geographical explanation.

## Exam technique
In exams, time and clarity matter. Begin by reading the question carefully and underlining command words and the data types referenced. Where a question asks you to use or evaluate specific techniques, name and justify the method you choose before presenting calculations or graphs. Show key working for statistical measures so that examiners can award method marks: if asked for a mean include the sum and the number of observations, and if a test is appropriate state the hypothesis and the rationale for the test. When presenting graphical evidence, ensure axes, units and legends are clear and refer to them in your explanation.

When interpreting results, go beyond numerical statements and explain the geographical meaning. For example, do not simply report a positive correlation; explain what the association implies about processes in the study area and whether the effect size is large enough to be of geographical interest. Comment on reliability and sampling: discuss sample size, representativeness and potential measurement error, linking this to how confident you are in the conclusions. If asked to evaluate field techniques, compare strengths and limitations in context and suggest concrete improvements. Use appropriate statistical vocabulary but avoid opaque jargon: examiners value clear, well-justified arguments that connect statistics to geography.

Finally, practise past paper questions and mark schemes. Familiarity with specimen papers will help you judge the depth of explanation expected and the balance between numerical work, diagrams and written evaluation. In the project–folio, adhere to word limits and present methods, results and analysis in a logical sequence with clear referencing for data sources. By combining sound statistical practice with clear, geographical explanation you will produce the concise, evidence-based answers that gain high marks.